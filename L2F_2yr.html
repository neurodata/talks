<!DOCTYPE html>
<html>
  <head>
    <title>L2M 2yr</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="fonts/quadon/quadon.css">
    <link rel="stylesheet" href="fonts/gentona/gentona.css">
    <link rel="stylesheet" href="slides_style_i.css">
    <script type="text/javascript" src="assets/plotly/plotly-latest.min.js"></script>
  </head>
  <body>
    <textarea id="source">



 

### Lifelong Learning Machines 

<br>      
<br>      
<br>      
<br>      
<br>      
<br>
<br>      

Joshua T. Vogelstein | {[BME](https://www.bme.jhu.edu/),[CIS](http://cis.jhu.edu/), [ICM](https://icm.jhu.edu/), [KNDI](http://kavlijhu.org/)}@[JHU](https://www.jhu.edu/) | [neurodata](https://neurodata.io)
<br>
[jovo&#0064;jhu.edu](mailto:j1c@jhu.edu) | <http://neurodata.io/talks> | [@neuro_data](https://twitter.com/neuro_data)





---
class: middle 

### Lifelong Learning Definition



---


## What is  Learning? 


"An algorithm $f$  learns from data $\mathcal{D}_n$  with performance measure $\mathcal{E}$ for task $t$, if $f$'s performance at $t$ improves with $n$.''


-- Tom Mitchell, 1997 (not exact quote)



---
 

## What are data?

- $z_i \in \mathcal{Z}$ for $i \in [n]$ are measurements
- Example 1: Classification
  -  $Z_i = (X_i,Y_i)$ where $\mathcal{X}=\mathbb{R}^p$ and $\mathcal{Y}=\lbrace 0,1\rbrace$ 





<!-- 

- Example 2: Reinforcment Learning
  - $Z$ is a sequence of states and actions + current state
  - $P$ a distribution over current states conditioned on 
      - past states 
      - past actions -->


---
 


## What is an Algorithm?

- $f_n$ is a  learner, which maps from a subset of $n$ samples to a hypothesis $h$
- $f=f_1, f_2, \ldots$ is a sequence of learners, called a (single task) learning algorithm 


$$f \in \mathcal{F}_{ST} = \lbrace  f_n : 2^{\mathcal{Z}^n} \rightarrow \mathcal{H}\rbrace$$ 





--



- Example 1: Classification
  - $f$ is *RandomForestClassifier.fit*
  - $h$ is *RandomForestClassifier.predict*

<!-- TODO@Ronak do i need both h and f? please make a compelling arguemtn for both yes and no :) -->


<!-- --



- Example 2: Reinforment Learning 
  - $f$
  - $h$ 
   -->


---


## What is Performance?

- Assume each measurement $Z_i \in \mathcal{D}$ is sampled identically and independentally (iid) from  $P$.
<!-- - some (complexity) constraints on  $f \in \mathcal{F}$, $f: \mathcal{Z}^n  \to \mathcal{H}$: -->
- Loss quantifies the error 
- Risk is a function of loss, eg, expected loss
- Performance is generalization error: the expected risk of an algorithm 
$$ \mathcal{E}(f,\mathcal{D}) := \mathbb{E}\_P[\mathcal{R}(f(\mathcal{D}))].$$
where the expectation is with respect to the training data.



---


## What is a Setting?

A setting is defined by a septuple $\mathcal{S} = \lbrace \mathcal{Z}, \mathcal{A}, \mathcal{L}, \mathcal{R}, \mathcal{P},  \mathcal{H},  \mathcal{F} \rbrace$

| Object | Notation | Example
|:--- |:--- |:--- | 
| Measurements  | $ \mathcal{Z}^n$ |  $\mathbb{R}^p \times \lbrace 0, 1 \rbrace$ |
| Actions |  $\mathcal{A}$ |  {↑,↓,&larr;, &rarr;,B,A,start}
| Loss  | $\mathcal{L}: \mathcal{A} \to \mathbb{R}_+$  | $ (\hat{y} - y_*)^2$
| Risk  | $\mathcal{R}: \mathcal{P} \times \mathcal{L}  \to \mathbb{R}_+$  | $\mathbb{E}_P[ \mathcal{L}(a)]$
| Distributions | $\mathcal{P} := \lbrace P_z \rbrace$ | Gaussian
| Hypotheses  | $\mathcal{H} = \lbrace h: \mathcal{Z} \to \mathcal{A} \rbrace$  | hyperplanes
| Algorithms | $\mathcal{F} = \lbrace f : 2^{\mathcal{Z}^n} \to \mathcal{H} \rbrace$  | *RandomForest.fit*


---

## Constraints 

$\mathcal{P}$, $\mathcal{H}$, and $\mathcal{F}$ are sets of constraints on learning 


| Constraint | Example | 
| :--- | :--- 
| interpretability | hyperplanes or sparse 
| complexity | $\mathcal{O}(n)$
| memory | $< 1$ gigabyte of memory for a given dataset
| time | $< 1$ sec on a specific hardware configuration for a given dataset
| scalability| must operate on distributed storage/compute
| power | $< 1$ watt on a given system for a given dataset 
| price | $< 1$ USD on a given system for a given dataset  
| hardware | must run on iPhone X


---


## What is a Task?

  <!-- - the learning algorithm $f= f_1, f_2, \ldots$  as the sequence that satisifies -->
  <!-- $$f \in \mathcal{F} = \lbrace 2^{\mathcal{Z}^n} \to \mathcal{H} \rbrace$$ -->

- Given 
  - a sample size $n$
  - a true but unknown distribution $P$.
  - a setting $\mathcal{S}$,


  Find $f$ that minimizes generalization error for a specified $n$, $P$, and $\mathcal{S}$

  $$f^* = \arg \min\_{f \in \mathcal{F}} \mathcal{E}(f,\mathcal{D}).$$
  
  <!-- TODO@ronak n, P, and S are implicit in the above equation, maybe they shouldn't be? -->
  
<br>  

- the constraints on $\mathcal{P}$ and $\mathcal{H}$ can be encoded into constraints on $\mathcal{F}$.
- the context is the other parts of a problem: $\lbrace \mathcal{Z}, \mathcal{A}, \mathcal{L}, \mathcal{R} \rbrace$.


---


## What is Learning?



Letting $\mathcal{D}_0$ be a data corpus with no samples,


.center[$f$ learns from data $\mathcal{D}$ iff $\mathcal{E}(f,\mathcal{D}) < \mathcal{E}(f,\mathcal{D}_0),$]





$\mathcal{E}(f,\mathcal{D}_0)$ is the initial performance of $f$ prior to seeing data, and therefore a function of
  - prior on $\theta$ 
  - inductive bias of $\mathcal{H}$
  - estimation bias of $f$
  - model bias of $\mathcal{P}$





---


## A Transfer Learning Task? 


- Let 
  - $t_i \in \lbrace 0, 1 \rbrace$ label each sample
  - $\mathcal{D}_0 = \lbrace (Z_i, T_i) : T_j = 0 \rbrace$ denote the .ye[target] data 
  - $\mathcal{D} = \lbrace (Z_i, T_i) \, \forall i \in [n] \rbrace$
  - $\mathcal{Z}' = (\mathcal{Z},\lbrace 0,1 \rbrace)$
- Assume $(Z_i,T_i)$  is sampled iid from $P$ and $Z_i | T_i=j \sim P_j$
- Define a transfer learning algorithm $f=f_1, f_2, \ldots$ as any sequence where 

$$ \mathcal{F}_{TL} = \lbrace f_n : 2^{(\mathcal{Z} \times \lbrace 0,1 \rbrace )^n} \rightarrow \mathcal{H} \rbrace$$

- Given
  - a sample size $n$
  - a true but unknown $P = \pi_0 P_0 + \pi_1 P_1$. 
  - a target setting $\mathcal{S} := \mathcal{S}\_{TL} = \lbrace \mathcal{Z}', \mathcal{A}, \mathcal{L}, \mathcal{R}, \mathcal{P},  \mathcal{H},  \mathcal{F}\_{TL} \rbrace$


<!-- - Let $P= \pi_0 P_0 + \pi_1 P_1$, where $P_0$ is the distribution of target data, and  -->

<!-- "An algorithm $f$  .ye[transfer] learns from data $\mathcal{D}_j$  with respect to transfer learning task $t$ with performance measure $\mathcal{E}^t$, if $f$'s performance at task  $t$ improves  with $\mathcal{D}_j$." -->

---


## What is Transfer Learning? 


Find the transfer learning algorithm $f$ that minimizes generalization error for the given $n$, $P$, and $\mathcal{S}$:

$$f^* = \arg \min\_{f \in \mathcal{F}_{TL}} \mathcal{E}(f,\mathcal{D}).$$

<br> 

$f$ .ye[transfer] learns for a given $n$, $P$, and $\mathcal{S}$ when 
$\mathcal{E}(f,\mathcal{D}) < \mathcal{E}(f,\mathcal{D}_0).$



      
---



## What is a Multitask? 



- Let  
  - $t_i \in [J]$ denote the task associated with sample $i$
  - $\mathcal{D}\_j = \lbrace (Z\_i, T\_i) : T\_i = j \rbrace$
  - $\mathcal{D} =  \cup\_{j \in [J]} \mathcal{D}\_j$
- Assume $(Z_i,T_i)$  is sampled iid from $P$ and $Z_i | T_i=j \sim P_j$
- Define a multitask learning algorithm  as the sequence $f=f_1,f_2,\ldots$ where 

$$f \in  \mathcal{F}_{MT} = \lbrace f_n : 2^{(\mathcal{Z} \times [J] )^n} \rightarrow \mathcal{H}\rbrace$$ 

- Given
  - a sample size $n$
  - a multi-setting $\mathcal{S} =  \lbrace \mathcal{S}_1, \mathcal{S}_2, \ldots, \mathcal{S}_J \rbrace$
  - a true but unknown mixture distibution $P = \sum_{j \in [J]} \pi_j P_j$. 



---


## What is Multitask Learning? 


Find $f$ that minimizes generalization error for the given $n$, $P$, and $\mathcal{S}$:

$$f^* = \arg \min\_{f \in \mathcal{F}_{MT}} \mathcal{E}(f,\mathcal{D}).$$



$f$  weakly .ye[multitask] learns from $\mathcal{D} \sim P$ in multi-setting $\mathcal{S}$ with sample size $n$ when

$$  \sum\_{j \in [J]} \mathcal{E}(f,\mathcal{D} \mid j ) P(j) <  \sum\_{j \in [J]} \mathcal{E}(f,\mathcal{D}_j \mid j) P(j),$$ 

<br>

and $f$ strongly .ye[multitask] learns from $\mathcal{D} \sim P$ in multi-setting $\mathcal{S}$ with sample size $n$  when 

$$ \mathcal{E}(f,\mathcal{D} \mid j) < \mathcal{E}(f,\mathcal{D}_j \mid j) \quad \forall j \in [J].$$ 


<!-- TODO@ronak i think n is implicit here. should we make it explicit? -->

---


## What is Sequential Learning? 

Same as "batch" learning, except $f$ updates existing hypothesis on basis of new data, that is, 


$$\mathcal{F}_S = \lbrace  f : \mathcal{H} \times 2^{\mathcal{Z}^n} \rightarrow \mathcal{H} \rbrace$$ 


Find the $f \in \mathcal{F}_{S}$ that minimizes generalization error for a given $n$, $P$, and setting $\mathcal{S}$:

$$f^* = \arg \min\_{f \in \mathcal{F}_{S}} \mathcal{E}(f,\mathcal{D}).$$


<!-- TODO@ronak do i need something else here? like a sequence of n's? -->


---


## What is a Lifelong  Task? 





Sequential multi-task learning, where
- $|\mathcal{J}|$ is (countably) infinite
- $J_n$ is the number of tasks observed after $n$ samples
- Requires .ye[out of task] capabilities  



---


## What is a Lifelong  Task? 




- Let  
  - $t_i \in$ .r[$\mathcal{J}$] denote the task associated with sample $i$
  - $\mathcal{D} =  \cup\_{j \in [J_n]} \mathcal{D}\_j$
- Assume $(Z_i,T_i)$  is sampled iid from $P$ and $Z_i | T_i=j \sim P_j$
- Define a lifelong learning algorithm  as the sequence $f=f_1,f_2,\ldots$ where 

$$f \in  \mathcal{F}_{L2} = \lbrace f_n : \mathcal{H} \times  2^{(\mathcal{Z} \times [J] )^n} \rightarrow \mathcal{H}\rbrace$$ 

- Given
  - a sample size $n$
  - a lifelong setting $\mathcal{S} =  \lbrace \mathcal{S}\_1, \mathcal{S}\_2, \ldots, \mathcal{S}\_{J_n} \rbrace$
  - a true but unknown mixture distibution $P = \sum_{j \in [J_n]} \pi_j P_j$. 


---



## What is Lifelong Learning? 



Find the lifelong learning algorithm $f$ that minimizes generalization error for the given $n$, $P$, and $\mathcal{S}$:

$$f^* = \arg \min\_{f \in \mathcal{L2}} \mathcal{E}(f,\mathcal{D}).$$


$f$  weakly .ye[lifelong] learns from $\mathcal{D} \sim P$ in setting $\mathcal{S}$ if

$$  \sum\_{j \in [J\_n]} \mathcal{E}(f,\mathcal{D} \mid j ) P(T=j) <  \sum\_{j \in [J\_n]} \mathcal{E}(f,\mathcal{D}\_j \mid j) P(T=j),$$ 

<br>


and $f$  strongly .ye[lifelong] learns from $\mathcal{D} \sim P$ in setting $\mathcal{S}$ if



$$ \mathcal{E}(f,\mathcal{D} \mid j) < \mathcal{E}(f,\mathcal{D}_j \mid j) \quad \forall j \in [J_n].$$ 




---
class: middle 

### Lifelong Learning Scenarios

---

## Ways Tasks can Differ


| Component | Change |
| :--- | :--- 
| $\mathcal{Z}$ | {smaller, bigger, different}
| $\mathcal{A}$ | {smaller, bigger, different}
| $\mathcal{L}$ | {different}
| $\mathcal{R}$ | {different}
| $\mathcal{P}$ | {smaller, bigger, different}
| $\mathcal{H}$ | {smaller, bigger, different}
| $\mathcal{F}$ | {smaller, bigger, different}
| $P$ | {different}
| $T_i$ | {always, never, sometimes} known


---

## Ways to Lifelong Learn

- There are $4\times4\times2\times2\times4\times4\times4\times2\times3 \approx 24$,$000$ ways that 2 tasks can differ.
- Let $\mathcal{C} = \lbrace \mathcal{P}, \mathcal{H}, \mathcal{F} \rbrace$ denote constraints, and simplify to denote only whether they have changed, not how.  This reduces by a factor of 32, bringing the total down to $\approx 750$. 
- Subsume loss into risk, because one can often change one instead of the other (eg, replace L2 with L1 norm vs replace mean with median), this brings it down to $384$.


---

## Ways Tasks can Differ


| Component | Change |
| :--- | :--- 
| $\mathcal{Z}$ | {smaller, bigger, different}
| $\mathcal{A}$ | {smaller, bigger, different}
| $\mathcal{R}$ | {different}
| $\mathcal{C}$ | {different}
| $P$ | {different}
| $T_i$ | {always, never, sometimes} known


---

## Examples

1. Known $\mathcal{A}$ changes, which implies that $P$ changes (CIFAR 10x10)
1. Unknown $P$ changes (continual learning)
1. Known $\mathcal{A}$ growing (incremental learning)


---
class: middle 

### Lifelong Learning Metrics


---


## Transfer Efficiency (TE)


The transfer efficiency of learning algorithm $f$ for task $j$ is
$$  TE\_j(f) := 
    \frac{\mathcal{E}\_j(f, \mathcal{D}_j)}{\mathcal{E}\_j(f, \mathcal{D_n})}.
$$

<br>

Algorithm $ f $ transfer learns if $ TE_j(f) > 1 $. 


---
 

## Forward / Reverse TE 


- Let $\mathcal{D}_F^j = \{(X_i, Y_i, T_i) \in \, \mathcal{D} : i \leq n_j\}$ be the set of all data up to sample $n_j$.
- Forward transfer efficiency of $ f $ for task $j$ is the improvement on task $j$ resulting from all data .ye[preceding] task $j$
$$    FTE_j(f) := 
\frac{\mathcal{E}_j(f, \mathcal{D}_j)}{\mathcal{E}_j(f, \mathcal{D}_F^j)}.
$$

--


<!-- ## Reverse Transfer Efficiency -->


<!-- Reverse Transfer Efficiency (RTE) for task $j$ measures the improvement on task $j$ resulting from all data occurring after the last sample $i$ with $T_i = j$.  -->


- Reverse transfer efficiency of $ f $ for task $j$ is the improvement on task $j$ resulting from all data .ye[after] task $j$ 


<!-- The reverse transfer efficiency of $ f $ for task $j$ is  -->
$$    RTE\_j(f) := 
\frac{\mathcal{E}\_j(f, \mathcal{D}_F^j)}{\mathcal{E}_j(f, \mathcal{D})}.
$$

---

## TE Factorizes


$$  TE\_j(f) := 
    \frac{\mathcal{E}\_j(f, \mathcal{D}_j)}{\mathcal{E}\_j(f, \mathcal{D_n})}
    = \frac{\mathcal{E}_j(f, \mathcal{D}_j)}{\mathcal{E}_j(f, \mathcal{D}_F^j)}
    \times
    \frac{\mathcal{E}\_j(f, \mathcal{D}_F^j)}{\mathcal{E}_j(f, \mathcal{D})}.
$$



---
class: middle 

### Algorithm



---
 

## Composable Hypotheses 

.center[ .ye[$h := w \circ v \circ u = w(v(u(x)))$]]

- Let $u$ be .ye[transformer] data to a new representation, 

$$ u : \mathcal{X}  \to \tilde{\mathcal{X}}$$

- Let $v$ be .ye[voter] which operate on the transformed data outputs votes on all possible actions 


$$ v : \tilde{\mathcal{X}} \to \mathcal{P}_{A|X}$$


- Let $w$ be .ye[decider] which decides which actions to take on the basis of the votes 


$$ w : \mathcal{P}_{A|X} \to \mathcal{A}$$


<!-- - $h=w(v(u(z)))$ -->



---
 


## Simple Examples

- Linear Discriminant Analysis (shallow)
  - $u$: projection onto a line 
  - $v$: fraction of points per over/under threshold
  - $w$: maximum a posteriori class 
--



- Decision Tree (deep)
 - $u$: union of polytopes
 - $v$: fraction of points per class per leaf node
 - $w$: maximum a posteriori class 

 
---


## Complicated Example


- Decision Forest 
  - $u_b$ for $B$ trees: union of overlapping polytopes
  - $v_b$ for $B$ trees: fraction of points per class per leaf node
  - $w$: maximum a posteriori class averaging over trees 
--




- Deep Nets 
  - $u$: "backbone" (all but last layer)
  - $v$: softmax layer
  - $w$: max 








---



## Key Idea 

- .ye[Different transformers can composed with  voters]
- Learn many different transformers $u_j(\cdot)$'s 
- For each $u\_j$, learn voter per task $v\_{j,j'}$'s 
- Use the decider to weight the various options 
- This is .ye[ensembling representations].

### Notes

- We learn new representation for each task 
- Dimensionality of internal representation grows linearly with number of tasks



<!-- TODO@jv: somewhere must introduce the concept of adjusting representations -->



---
 


## Composable Learning

<br> 

|  Scenario | Composition 
|  :--- | :--- 
| Single task learning | $ h(\cdot) = w \circ v \circ u (\cdot)$
| Multiple independent task learning | $ h_j(\cdot) = w_j \circ  v_j \circ u_j (\cdot)$ 
| Single task ensemble learning |$ h(\cdot) = w \circ \bigcup_j [ v_j \circ u_j (\cdot)] $ 
| Multitask learning | $ h_j(\cdot) = w_j \circ  v  \circ \bigcup_j  u_j (\cdot)$
| .ye[Multitask ensemble representation learning]  | $ h\_j(\cdot) = w\_j \circ  \bigcup\_{j'}  [v\_{j,j'}  \circ    u\_{j'} (\cdot) ] $




---
 

## Lifelong Learning Schema


![:scale 100%](images/learning-schemas.svg)

<!-- TODO@jv: add increasing complexity schema -->
<!-- TODO@jv: change to progressive? -->



- Any learner with an explicit internal representation is ok, 
  - e.g.,  decision trees, decision forests, deep networks 
- SVM, k-NN, etc., are not



---
 

## General Representations 

<br> 

.pull-left[
- Transformers learn representations 
- We desire representations that are sufficient for one task, and  useful for other tasks 
- Decision trees, decision forests, and deep nets (with ReLu nodes) .ye[partition] feature space into polytopes
]

--

.pull-right[
<img src="images/deep-polytopes.png" style="width:500px;"/>
]

<!-- - NNs with ReLu nodes  partitions feature space into  polytopes ([NIPS, 2014](http://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf)). -->





---
class: middle 

### Simulations



---


## A Transfer Example

- .ye[XOR]
  - Samples in the (0,0) and (1,1) quadrants are purple  
  - samples in the (0,1) and (1,0) quadrants are green 
- .lb[N-XOR]
  - Samples in the (0,0) and (1,1) quadrants are green  
  - samples in the (0,1) and (1,0) quadrants are purple 
- Optimal decision boundaries for both problems are coordinate axes

<img src="images/l2m_18mo/xor_nxor.png" style="width:475px" class="center"/> 



---


## Lifelong Classifier 

<img src="images/columbia20/xor-nxor-all.png"  style="height:300px;">


- .lb[Uncertainty Forest] uses 100 samples from XOR to learn partitions
<!-- - .orange[Transfer Forest] uses $n$ samples from N-XOR to learn partitions  -->
- .ye[Lifelong Forest] uses 100 samples from XOR and $n$ samples from N-XOR to learn partitions

<!-- TODO@hh: replace with four panel figure: 
  TOP LEFT: XOR
  TOP RIGHT: N-XOR
  BOTTOM LEFT: x-axis is simply # samples, and y-axis is Generalization Error, and we show 4 lines: E_1(D_1), E_1(D_n), E_2(D_2), E_2(D_n)
  BOTTOM RIGHT: x-axis is # of samples, maybe starting with n/2, y-axis is TE, two lines, TE_1 and TE_2   
-->


---


## Lifelong Classifier 

<img src="images/columbia20/xor-nxor-all2.png"  style="height:500px;">

---
 

## Different # of Classes 

<img src="images/spiral-all.png"  style="height:500px;">

<!-- TODO@hh: replace with same 4 panel figure as above -->

---
 

## Graceful Forgetting

<img src="images/rxor-suite-new-row.png"  style="width:700px;">




---
class: middle 

### Real Data 


---
 

## Consider an  example

.pull-left[
- *CIFAR 100* is a popular image classification dataset with 100 classes of images. 
- 500 training images and 100 testing images per class.
- All images are 32x32 color images.
- CIFAR 10x10 breaks the 100-class task problem into 10 tasks, each with 10-class.
]

.pull-right[
<img src="images/l2m_18mo/cifar-10.png" style="position:absolute; left:450px; width:400px;"/>
]

<!-- TODO@JD: replace CIFAR10 image with same thing but using CIFAR100 images and categories -->

---
 


## Previous State-of-the-Art


<img src="images/l2m_18mo/progressive_netsc.png" style="width:650px;"/>

Andrei A. Rusu et al. [Progressive Neural Networks](https://arxiv.org/abs/1606.04671), arXiv, 2016.
  
<!-- Seungwon Lee, James Stokes, and Eric Eaton. "[Learning Shared Knowledge for Deep Lifelong Learning Using Deconvolutional Networks](https://www.ijcai.org/proceedings/2019/393)." IJCAI, 2019. -->



---


Lifelong Forests demonstrates the .ye[largest forward transfer].


<!-- <img src="images/fte_cifar.png" style="height:530px;" /> -->
<!-- <img src="images/fte_cifar_2.png" style="height:550px;" /> -->

<!--  TODO@JD: replace with average FTE and add legend outside -->
<img src="images/CIFAR_FTE.png" style="height:550px;" /> 
---


## Reverse Transfer Efficiency

- y-axis indicates .ye[reverse transfer efficiency] (RTE), 
  - which is the ratio of "single task error" to "error using future tasks"
- each task will have a line
  - if the line .ye[increases], that means it is doing "reverse transfer"


---
 

Lifelong Forests .ye[uniquely exhibits reverse transfer].


<img src="images/CIFAR_RTE.png" style="height:530px;" />

<!-- TODO@JD: replace with average RTE and add legend outside -->


---
 

Lifelong Forests uniquely exhibits .ye[strong] lifelong learning.

| Algorithm  | Average TE | Min TE 
|:---        |:---       |:--- |
| LF         |  1.13 (&plusmn;0.01)   |  .ye[1.10] 
| DF-CNN     |  0.75 (&plusmn;0.08)   |  0.40   
| Online EWC |  0.96 (&plusmn;0.01)   |  0.88  
| EWC        |  0.97 (&plusmn;0.01)  |  0.91   
| SI         |  0.86 (&plusmn;0.02)   |  0.75   
| LwF        |  1.00 (&plusmn;0.01)   |  0.97   
| ProgNN     |  1.02 (&plusmn;0.01)   |  0.97   


<!-- <img src="images/all_TE.png" style="height:250px;" /> -->
<!-- <img src="images/all_TE_2.png" style="height:500px;" /> -->


---
class: center, middle


![:scale 70%](images/cifar_accuracy.png)

---
class: middle 

### Theory


---


## What do classifiers do?

<br>

learn: given $(x_i,y_i)$, for $i \in [n]$, where $y \in \lbrace 0,1 \rbrace$
1. partition feature space into "parts",
2. compute plurality  of points in each part.


predict: given $x$
2. find its part, 
3. report the plurality vote in its part.


---


## What can regressors do?

<br>

learn: given $(x_i,y_i)$, for $i \in [n]$, where $y \in \mathbb{R}$
1. partition feature space into "parts",
2. compute average of points in each part.


predict: given $x$
2. find its part,
3. report the average vote in its part.




---


## The fundamental theorem of statistical pattern recognition



If each part is:

1. small enough, and 
2. has enough points in it, 

then given enough data, one can learn *perfectly, no matter what*! 


$$\mathcal{E}\(f,\mathcal{D}) \rightarrow \mathcal{E}^*,$$

where $\mathcal{E}^*$is Bayes optimal.

-- Stone, 1977


<!-- NB: the parts can be overlapping (as in kNN) or not (as in histograms) -->



---


## The fundamental .ye[conjecture] of transfer learning


If each cell is:

- small enough, and 
- has enough points in it, 

then given enough data, one can .ye[transfer learn] *perfectly, no matter what*! 


-- jovo, 2020




---
class: middle 

### Discussion



---


##  Key Insights

  1. Avoiding catastrophic forgetting simply means reverse transfer is 1, but why stop there?
  2. Ensembling internal representations  enables reverse transfer > 1

---
 

## Limitations 

2. Tasks must be discrete 
3. Data must be batched into tasks 
4. Tasks must be known 
5. Feature space must be the same for all tasks 
6. Only unimodal data supported (e.g., images)
1. Internal representation grows linearly with # of tasks 
1. Must grow rather than recruit new internal representations       
      



---


##  Key Accomplishments


- Formalized Lifelong Learning as generalization of classical machine learning
- Introduced novel evaluation criteria: forward and reverse transfer efficiency
- Proposed generic lifelong learning algorithm framework by ensembling internal representations
- Implemented Lifelong Forests as a specific example 
- Demonstrated Lifelong Forests uniquely exhibits 
    - reverse transfer 
    - stong lifelong learning
- Conjectured theory promising to prove consistency and robustness




---


## References 

1. H. Helm et al. Lifelong Learning Forests, 2020
1. R. Mehta et al. A General Theory of Learnability, 2020. 
3. T. M. Tomita et al. [Sparse  Projection Oblique Randomer Forests](https://arxiv.org/abs/1506.03410). arXiv, 2018.
1. R Guo, et al. [Estimating Information-Theoretic Quantities with Uncertainty Forests](https://arxiv.org/abs/1907.00325). arXiv, 2019.
1. R. Perry, et al. Manifold Forests: Closing the Gap on Neural Networks. preprint, 2019.
1. C. Shen and J. T. Vogelstein. [Decision Forests Induce Characteristic Kernels](https://arxiv.org/abs/1812.00029). arXiv, 2018
7. J. Browne et al. [Forest Packing: Fast, Parallel Decision Forests](https://arxiv.org/abs/1806.07300). SIAM ICDM, 2018.
1. M. Madhya, et al. [Geodesic Learning via Unsupervised Decision Forests](https://arxiv.org/abs/1907.02844). arXiv, 2019.

More info: [https://neurodata.io/sporf/](https://neurodata.io/sporf/)




---
 

### Acknowledgements



<!-- <div class="small-container">
  <img src="faces/ebridge.jpg"/>
  <div class="centered">Eric Bridgeford</div>
</div>

<div class="small-container">
  <img src="faces/pedigo.jpg"/>
  <div class="centered">Ben Pedigo</div>
</div>

<div class="small-container">
  <img src="faces/jaewon.jpg"/>
  <div class="centered">Jaewon Chung</div>
</div> -->


<div class="small-container">
  <img src="faces/yummy.jpg"/>
  <div class="centered">yummy</div>
</div>

<div class="small-container">
  <img src="faces/lion.jpg"/>
  <div class="centered">lion</div>
</div>

<div class="small-container">
  <img src="faces/violet.jpg"/>
  <div class="centered">baby girl</div>
</div>

<div class="small-container">
  <img src="faces/family.jpg"/>
  <div class="centered">family</div>
</div>

<div class="small-container">
  <img src="faces/earth.jpg"/>
  <div class="centered">earth</div>
</div>


<div class="small-container">
  <img src="faces/milkyway.jpg"/>
  <div class="centered">milkyway</div>
</div>


##### JHU

<div class="small-container">
  <img src="faces/cep.png"/>
  <div class="centered">Carey Priebe</div>
</div>

<!-- <div class="small-container">
  <img src="faces/randal.jpg"/>
  <div class="centered">Randal Burns</div>
</div> -->


<!-- <div class="small-container">
  <img src="faces/cshen.jpg"/>
  <div class="centered">Cencheng Shen</div>
</div> -->


<!-- <div class="small-container">
  <img src="faces/bruce_rosen.jpg"/>
  <div class="centered">Bruce Rosen</div>
</div>


<div class="small-container">
  <img src="faces/kent.jpg"/>
  <div class="centered">Kent Kiehl</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/mim.jpg"/>
  <div class="centered">Michael Miller</div>
</div>

<div class="small-container">
  <img src="faces/dtward.jpg"/>
  <div class="centered">Daniel Tward</div>
</div> -->


<!-- <div class="small-container">
  <img src="faces/vikram.jpg"/>
  <div class="centered">Vikram Chandrashekhar</div>
</div>


<div class="small-container">
  <img src="faces/drishti.jpg"/>
  <div class="centered">Drishti Mannan</div>
</div> -->

<div class="small-container">
  <img src="faces/jesse.jpg"/>
  <div class="centered">Jesse Patsolic</div>
</div>

<!-- <div class="small-container">
  <img src="faces/falk_ben.jpg"/>
  <div class="centered">Benjamin Falk</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/kwame.jpg"/>
  <div class="centered">Kwame Kutten</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/perlman.jpg"/>
  <div class="centered">Eric Perlman</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/loftus.jpg"/>
  <div class="centered">Alex Loftus</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/bcaffo.jpg"/>
  <div class="centered">Brian Caffo</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/minh.jpg"/>
  <div class="centered">Minh Tang</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/avanti.jpg"/>
  <div class="centered">Avanti Athreya</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/vince.jpg"/>
  <div class="centered">Vince Lyzinski</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/dpmcsuss.jpg"/>
  <div class="centered">Daniel Sussman</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/youngser.jpg"/>
  <div class="centered">Youngser Park</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/shangsi.jpg"/>
  <div class="centered">Shangsi Wang</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/tyler.jpg"/>
  <div class="centered">Tyler Tomita</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/james.jpg"/>
  <div class="centered">James Brown</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/disa.jpg"/>
  <div class="centered">Disa Mhembere</div>
</div> -->

<!-- <div class="small-container">
  <img src="faces/gkiar.jpg"/>
  <div class="centered">Greg Kiar</div>
</div> -->


<!-- <div class="small-container">
  <img src="faces/jeremias.png"/>
  <div class="centered">Jeremias Sulam</div>
</div> -->


<div class="small-container">
  <img src="faces/meghana.png"/>
  <div class="centered">Meghana Madhya</div>
</div>
  

<!-- <div class="small-container">
  <img src="faces/percy.png"/>
  <div class="centered">Percy Li</div>
</div>
-->

<div class="small-container">
  <img src="faces/hayden.png"/>
  <div class="centered">Hayden Helm</div>
</div>


<div class="small-container">
  <img src="faces/rguo.jpg"/>
  <div class="centered">Richard Gou</div>
</div>

<div class="small-container">
  <img src="faces/ronak.jpg"/>
  <div class="centered">Ronak Mehta</div>
</div>

<div class="small-container">
  <img src="faces/jayanta.jpg"/>
  <div class="centered">Jayanta Dey</div>
</div>

##### Microsoft Research

<div class="small-container">
  <img src="faces/chwh-180x180.jpg"/>
  <div class="centered">Chris White</div>
</div>


<div class="small-container">
  <img src="faces/weiwei.jpg"/>
  <div class="centered">Weiwei Yang</div>
</div>

<div class="small-container">
  <img src="faces/jolarso150px.png"/>
  <div class="centered">Jonathan Larson</div>
</div>

<div class="small-container">
  <img src="faces/brtower-180x180.jpg"/>
  <div class="centered">Bryan Tower</div>
</div>


##### DARPA 
Hava, Ben, Robert, Jennifer, Ted.

</div>
<!-- <img src="images/funding/nsf_fpo.png" STYLE="HEIGHT:95px;"/> -->
<!-- <img src="images/funding/nih_fpo.png" STYLE="HEIGHT:95px;"/> -->
<!-- <img src="images/funding/darpa_fpo.png" STYLE=" HEIGHT:95px;"/> -->
<!-- <img src="images/funding/iarpa_fpo.jpg" STYLE="HEIGHT:95px;"/> -->
<!-- <img src="images/funding/KAVLI.jpg" STYLE="HEIGHT:95px;"/> -->
<!-- <img src="images/funding/schmidt.jpg" STYLE="HEIGHT:95px;"/> -->

---
class:center

<img src="images/l_and_v.jpeg" style=" height:600px;"/>

---
class: middle, inverse


## .center[Extra Slides]



---
class: middle

# Summary


---


## What is Lifelong Learning?

A computational system .ye[lifelong learns] from data if, given a stream of data and tasks, data associated with one task is used to improve performance on both past and future tasks. 


---


## What is Lifelong Learning?

A computational system .ye[lifelong learns] from data if, given a stream of data and tasks, data associated with one task is used to improve performance on both past and future tasks. 


Motivation: in biology, learning subsequent tasks often improves performance on previously learned tasks 


The key is learning internal representations of each data sample that is useful for multiple tasks


---


## Current State of the Art 

1. Used fixed architecture, finite capacity
2. Increase capacity, with complicated architecture 


---


## Our Approach 


1. Formally define lifelong learning as a generalization of single task machine learning, with suitable metrics 
2. Develop a generic lifelong learning approach, Omni-Directional Ensembling Representation (ODER)
  1. Learn a new representation for each task
  2. Ensemble all representations to make predictions 
3. Implement a specific example of this approach, Lifelong Forests 
4. Demonstrate that Lifelong Forests uniquely demonstrates lifelong learning



---


## Evaluation Criteria ("Metrics")


**Transfer Efficiency**: Performance on a task with only task-specific data, normalized by performance on the task including lots of other data.

**Forward Transfer Efficiency**: Performance on a task with only task-specific data, normalized by performance on the task including .ye[all past data]. 

**Reverse Transfer Efficiency**: Performance on a task with only up until and including task-specific data, normalized by performance on .ye[all data, both past and future].

--

If you don't reverse transfer, you haven't lifelong learned.


---
 

.ye[Lifelong Forests] uniquely exhibits reverse transfer.


<img src="images/cifar-rte.png" style="height:530px;" />


      


---
class: middle 

# Biology


---
 

## Do brains do it?

--

(brains obviously learn)

1. Do brains partition feature space?
2. Is there some kind of "voting" occurring within each part?


---


## Brains partition  

- Feature space = the set of all possible inputs to a brain
- Partition = only a subset of "nodes" respond to any given input
- Examples
  1. visual receptive fields
  2. place fields / grid cells
  3. sensory homonculus

<br>

<img src="images/rock20/Side-black.gif" style="height:230px;"/>
<img src="images/rock20/Front_of_Sensory_Homunculus.gif" style="height:230px;"/>
<img src="images/rock20/Rear_of_Sensory_Homunculus.jpg" style="height:230px;"/>


---


## Brains vote

- Vote = pattern of responses indicate which stimulus evoked response

<img src="images/rock20/brody1.jpg" style="height:400px;" />



---
 

## Can Humans Reverse Transfer?


- "Knowledge and skills from a learner’s first language are used and reinforced, deepened, and expanded upon when a learner is engaged in second language literacy tasks." -- [American Council on the Teaching of Foreign Languages](https://www.actfl.org/guiding-principles/literacy-language-learning)



---
 

## Proposed Experiments 

- Behavioral Experiment
  - Source Task: Delayed Match to Sample (DMS) on colors
  - Target Task A: Delayed Match to Not-Sample  on colors 
  - Target Task B: DMS on orientation 
- Measurements
  - Arc-GFP to identify which neurons could learn 
  - Ca2+-YFP to measure neural activity
  - Narp-RFP to identify which neurons actually consolidate
- Species 
      - Zebrafish (Engert)
      - Mouse (McNaughton and/or Tolias)
      - Human (Isik)






---
class: middle 

# Other Stuff



---


## Not So Clevr

<img src="images/not-so-clevr.png" style="width:650px" />




---

### RF is more computationally efficient 


<img src="images/s-rerf_6plot_times.png" style="width:750px;"/>




</textarea>
<!-- <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script> -->
<!-- <script src="remark-latest.min.js"></script> -->
<script src="remark-latest.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
<script type="text/javascript">

  var options = {};
  var renderMath = function() {
    renderMathInElement(document.body);
    // or if you want to use $...$ for math,
    renderMathInElement(document.body, {delimiters: [ // mind the order of delimiters(!?)
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\[", right: "\\]", display: true},
        {left: "\\(", right: "\\)", display: false},
    ]});
  }

  remark.macros.scale = function (percentage) {
    var url = this;
    return '<img src="' + url + '" style="width: ' + percentage + '" />';
  };

  // var slideshow = remark.create({
  // Set the slideshow display ratio
  // Default: '4:3'
  // Alternatives: '16:9', ...
  // {
  // ratio: '16:9',
  // });

  var slideshow = remark.create(options, renderMath);


</script>
</body>
</html>
